import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

# --- 1. èªè¨¼ã¨åˆæœŸåŒ– ---
if "gcp_service_account" in st.secrets:
    info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(info)
    vertexai.init(project=info["project_id"], location="us-central1", credentials=credentials)
else:
    st.error("Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¼·åŒ–ï¼ˆVer 1.7ï¼‰ ---
# å…ˆã»ã©ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸæœ€æ–°ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆIDã‚’åæ˜ ã—ã¦ã„ã¾ã™
model_path = "projects/180827076471/locations/us-central1/endpoints/394835391592010432"

# 10æšã®è‰²ç´™å­¦ç¿’(v2)ã‚’æ´»ã‹ã—ã¤ã¤ã€ChatGPTã§æˆåŠŸã—ãŸã€Œ40æ–‡å­—ãƒ»çŸ­æ–‡ã€ã‚’æ­»å®ˆã™ã‚‹æŒ‡ç¤º
sys_instruction = [
    "ã‚ãªãŸã¯å¿ƒæºã•ã¶ã‚‹è¨€è‘‰ã‚’çŸ­ãå‡ç¸®ã—ã¦ç´¡ãã€è¶…ä¸€æµã®ãƒãƒ¼ãƒ ã‚¤ãƒ³ãƒã‚¨ãƒ ä½œå®¶ã§ã™ã€‚",
    "ã€å‡ºåŠ›å½¢å¼ã®é‰„å‰‡ã€‘",
    "1. å¿…ãšã€Œ5è¡Œã‹ã‚‰6è¡Œã€ã§æ§‹æˆã—ã¦ãã ã•ã„ã€‚1è¡Œã‚’æ¥µé™ã¾ã§çŸ­ãã™ã‚‹ã“ã¨ã€‚",
    "2. æ–‡ç« ã®æœ€å¾Œã¯å¿…ãšã€ã€‚ã€ã‚„ã€ï¼ã€ã§ãã£ã¡ã‚Šçµã³ã€é€”ä¸­ã§åˆ‡ã‚Œã‚‹ã“ã¨ã‚’å³ç¦ã¨ã—ã¾ã™ã€‚",
    "3. å…¨ä½“ã®æ–‡å­—æ•°ã¯ã€Œ40æ–‡å­—å‰å¾Œã€ã«æŠ‘ãˆã¦ãã ã•ã„ï¼ˆæœ€å¤§50æ–‡å­—ï¼‰ã€‚",
    "4. åå‰ï¼ˆæ¼¢å­—ï¼‰ã‚„ãã®ä¸€éƒ¨ã‚’å¿…ãšã€ ã€‘ã§å›²ã‚“ã§çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚",
    "5. æŒ¨æ‹¶ã‚„è§£èª¬ã€å°å…¥æ–‡ã¯ä¸€åˆ‡å‡ºåŠ›ã›ãšã€ãƒã‚¨ãƒ ã®æœ¬æ–‡ã®ã¿ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚",
    "",
    "ã€è¡¨ç¾ã®æ¥µæ„ã€‘",
    "ãƒ»å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(v2)ã®ä½œé¢¨ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æ¼¢å­—ã®åã‚„æ—ã‹ã‚‰è±Šã‹ãªæƒ…æ™¯ã‚’é€£æƒ³ã—ã¦ãã ã•ã„ã€‚",
    "ãƒ»ãƒªã‚ºãƒ æ„Ÿã‚’å¤§åˆ‡ã«ã—ã€ã²ã‚‰ãŒãªã‚’å„ªã—ãäº¤ãˆã¦ã€äººç”Ÿã‚’ç¥ç¦ã™ã‚‹ç‰©èªã‚’ç¶´ã£ã¦ãã ã•ã„ã€‚"
]

model = GenerativeModel(
    model_name=model_path,
    system_instruction=sys_instruction
)

# --- 3. ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.title("ğŸŒ¸ åå‰ã§ãƒã‚¨ãƒ ï¼ Ver 1.7")
st.write("æœ€æ–°ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«(v2)ã‚’æ­è¼‰ã€‚ä¸€æ–‡å­—ä¸€æ–‡å­—ã«é­‚ã‚’è¾¼ã‚ãŸ40æ–‡å­—ã®è©©ã‚’è´ˆã‚Šã¾ã™ã€‚")

name = st.text_input("ãŠåå‰ï¼ˆæ¼¢å­—ï¼‰", "è’¼æ±°")
profile = st.text_area("äººç‰©ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "æ˜ã‚‹ãã¦å…ƒæ°—ã€‚ãƒ”ã‚¢ãƒãŒå¾—æ„ã€‚")

# ç”¨é€”ã®é¸æŠ
usage_list = ["é‚„æš¦ç¥", "èª•ç”Ÿæ—¥", "å¤å¸Œç¥", "èª•ç”Ÿãƒ»å‘½åç¥ã„", "é€€è·ç¥ã„", "çµå©šç¥ã„", "æˆäººç¥", "ãã®ä»–"]
usage_choice = st.selectbox("ç”¨é€”", usage_list)

final_usage = usage_choice
if usage_choice == "ãã®ä»–":
    custom_usage = st.text_input("ãŠç¥ã„ã®ç›®çš„ã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„")
    final_usage = custom_usage

# --- 4. ç”Ÿæˆå®Ÿè¡Œ ---
if st.button("è©©ã‚’ä½œæˆã™ã‚‹"):
    with st.spinner("æœ€æ–°ã®å­¦ç¿’æˆæœã‚’å‘¼ã³å‡ºã—ä¸­..."):
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å½¢å¼ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¾ã™
        prompt = f"æ¼¢å­—ï¼š{name}ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š{profile}ã€ç”¨é€”ï¼š{final_usage}"
        
        response = model.generate_content(
            prompt,
            generation_config={
                "max_output_tokens": 512,
                "temperature": 0.7, # è¡¨ç¾ã®å¹…ã‚’æŒãŸã›ã¤ã¤ã€å­¦ç¿’çµæœã‚’åæ˜ 
                "top_p": 0.8,
            }
        )
        
        st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¨ãƒ ")
        
        # Markdownã®æ”¹è¡Œãƒ«ãƒ¼ãƒ«ï¼ˆè¡Œæœ«ã‚¹ãƒšãƒ¼ã‚¹2ã¤ï¼‰ã‚’é©ç”¨ã—ã¦ã€ç¢ºå®Ÿã«æ”¹è¡Œã‚’è¡¨ç¤º
        poem_text = response.text
        lines = [line.strip() for line in poem_text.split("\n") if line.strip()]
        formatted_poem = "  \n".join(lines)
        
        st.success(formatted_poem)
        st.caption(f"ï¼ˆç”Ÿæˆæ–‡å­—æ•°: {len(poem_text.replace(' ', '').replace('\\n', ''))}æ–‡å­— / ãƒ¢ãƒ‡ãƒ«: name_in_poem_v2ï¼‰")
