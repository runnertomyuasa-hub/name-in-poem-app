import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

# --- 1. èªè¨¼ã¨åˆæœŸåŒ– ---
if "gcp_service_account" in st.secrets:
    info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(info)
    
    # Secretsã‹ã‚‰èª­ã¿å–ã£ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’ãã®ã¾ã¾ä½¿ç”¨
    target_project = info["project_id"]
    vertexai.init(project=target_project, location="us-central1", credentials=credentials)
else:
    st.error("Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Streamlitç®¡ç†ç”»é¢ã®Secretsã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆVer 2.1ï¼‰ ---
# æœ€æ–°ã®IDã€Œ394835391592010432ã€ã‚’ç¢ºå®Ÿã«æŒ‡å®š
endpoint_id = "394835391592010432"
model_path = f"projects/{target_project}/locations/us-central1/endpoints/{endpoint_id}"

sys_instruction = [
    "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒãƒ¼ãƒ ã‚¤ãƒ³ãƒã‚¨ãƒ ä½œå®¶ã§ã™ã€‚",
    "40æ–‡å­—å‰å¾Œã®5ã€œ6è¡Œè©©ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
    "ã€é‡è¦ã€‘å¿…ãšæ”¹è¡Œã‚’å«ã‚ã¦ãã ã•ã„ã€‚"
]

try:
    model = GenerativeModel(
        model_name=model_path,
        system_instruction=sys_instruction
    )
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

# --- 3. ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.title("ğŸŒ¸ åå‰ã§ãƒã‚¨ãƒ ï¼ Ver 2.1")
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤ºã—ã¦ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™
with st.sidebar:
    st.write("### æ¥ç¶šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
    st.info(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {target_project}")
    st.info(f"ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæœ«å°¾: ...{endpoint_id[-4:]}")

name = st.text_input("ãŠåå‰ï¼ˆæ¼¢å­—ï¼‰", "è’¼æ±°")
profile = st.text_area("äººç‰©ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "æ˜ã‚‹ãã¦å…ƒæ°—ã€‚ãƒ”ã‚¢ãƒãŒå¾—æ„ã€‚")

# --- 4. ç”Ÿæˆå®Ÿè¡Œ ---
if st.button("è©©ã‚’ä½œæˆã™ã‚‹"):
    with st.spinner("AIãŒè¨€è‘‰ã‚’ç´¡ã„ã§ã„ã¾ã™..."):
        try:
            prompt = f"æ¼¢å­—ï¼š{name}ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š{profile}"
            response = model.generate_content(
                prompt,
                generation_config={"max_output_tokens": 512, "temperature": 0.7}
            )
            
            # çµæœè¡¨ç¤ºï¼ˆæ”¹è¡Œã‚’åæ˜ ï¼‰
            st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¨ãƒ ")
            st.success(response.text.replace("\n", "  \n"))
            
        except Exception as e:
            st.error("ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.code(f"è¨ºæ–­ç”¨ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{e}")
