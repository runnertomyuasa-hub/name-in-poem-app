import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

# --- 1. èªè¨¼ã¨åˆæœŸåŒ– ---
if "gcp_service_account" in st.secrets:
    info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(info)
    vertexai.init(project=info["project_id"], location="us-central1", credentials=credentials)
else:
    st.error("Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆã“ã“ã«å¼·åŠ›ãªæŒ‡ç¤ºã‚’å…¥ã‚Œã¾ã™ï¼‰ ---
model_path = "projects/180827076471/locations/us-central1/endpoints/4782082832941973504"

# ã“ã‚ŒãŒã€Œç›£ç£ã®æŒ‡ç¤ºï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ã€ã§ã™
sys_instruction = [
    "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒãƒ¼ãƒ ã‚¤ãƒ³ãƒã‚¨ãƒ ä½œå®¶ã§ã™ã€‚",
    "ã€é‡è¦ãªãƒ«ãƒ¼ãƒ«ã€‘",
    "1. åå‰ï¼ˆæ¼¢å­—ï¼‰ã®æ–‡å­—ãã®ã‚‚ã®ã€ã‚ã‚‹ã„ã¯ãã®æ¼¢å­—ã®ã€è¾ºï¼ˆã¸ã‚“ï¼‰ã€ã‚„ã€å† ï¼ˆã‹ã‚“ã‚€ã‚Šï¼‰ã€ã‚’å¿…ãšã€ ã€‘ã§å›²ã‚“ã§è©©ã®ä¸­ã«çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚",
    "2. æ§‹æˆã¯ã€å¿…ãšã€5ã€œ6è¡Œã€ã®è©©ã«ã—ã¦ãã ã•ã„ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šå°‘ã—é•·ã‚ã«æƒ…æ™¯ã‚’æå†™ã—ã¦ãã ã•ã„ã€‚",
    "3. æŒ¨æ‹¶ï¼ˆã€ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ã€ç­‰ï¼‰ã‚„è§£èª¬ã€å°å…¥æ–‡ã¯ä¸€åˆ‡å‡ºåŠ›ã—ãªã„ã§ãã ã•ã„ã€‚è©©ã®æœ¬æ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚",
    "4. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä½œé¢¨ã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚"
]

model = GenerativeModel(
    model_name=model_path,
    system_instruction=sys_instruction
)

# --- 3. ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.title("ğŸŒ¸ åå‰ã§ãƒã‚¨ãƒ ï¼")
st.write("ãƒ—ãƒ­ã®ä½œé¢¨ã‚’å­¦ç¿’ã—ãŸAIãŒã€ãŠåå‰ã«åˆã‚ã›ãŸ5ã€œ6è¡Œã®è©©ã‚’ä½œæˆã—ã¾ã™ã€‚")

name = st.text_input("ãŠåå‰ï¼ˆæ¼¢å­—ï¼‰", "å°äº”éƒ")
profile = st.text_area("äººç‰©ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "å‹‡ã¾ã—ã„å¤§å·¥ã•ã‚“ã€‚ãƒ”ã‚¢ãƒã‚‚å¾—æ„ã€‚")

# ç”¨é€”ã‚’ç´°åˆ†åŒ–
usage_list = ["èª•ç”Ÿæ—¥", "é‚„æš¦ç¥", "å¤å¸Œç¥", "é•·å¯¿ç¥", "é€€è·ç¥ã„", "çµå©šç¥ã„", "æˆäººç¥", "ãã®ä»–"]
usage_choice = st.selectbox("ç”¨é€”", usage_list)

final_usage = usage_choice
if usage_choice == "ãã®ä»–":
    custom_usage = st.text_input("ãŠç¥ã„ã®ç›®çš„ã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„")
    final_usage = custom_usage

# --- 4. ç”Ÿæˆå®Ÿè¡Œ ---
if st.button("è©©ã‚’ä½œæˆã™ã‚‹"):
    with st.spinner("ãƒ—ãƒ­ã®ä½œé¢¨ã‚’å†ç¾ä¸­..."):
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(JSONL)ã¨å…¨ãåŒã˜ã€Œã‚¿ã‚°å½¢å¼ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¾ã™
        prompt = f"æ¼¢å­—ï¼š{name}ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š{profile}ã€ç”¨é€”ï¼š{final_usage}"
        
        # è‡ªç”±ãªç™ºæƒ³ã‚’æŠ‘ãˆã€å­¦ç¿’å†…å®¹ã«é›†ä¸­ã•ã›ã‚‹è¨­å®š(temperature=0.0)
        response = model.generate_content(
            prompt,
            generation_config={
                "max_output_tokens": 1024,
                "temperature": 0.0,
            }
        )
        
        st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¨ãƒ ")
        st.info(response.text)
