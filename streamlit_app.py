import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

# --- 1. èªè¨¼ã¨åˆæœŸåŒ– ---
if "gcp_service_account" in st.secrets:
    info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(info)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·(180827076471)ã‚’ä½¿ç”¨ã—ã¦åˆæœŸåŒ–
    vertexai.init(project="180827076471", location="us-central1", credentials=credentials)
else:
    st.error("Secretsè¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆVer 1.9ï¼‰ ---
# ã€æœ€é‡è¦ã€‘ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDåã§ã¯ãªãã€æ•°å­—ã®ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã€ã‚’ãƒ‘ã‚¹ã«ä½¿ç”¨ã—ã¾ã™
model_path = "projects/180827076471/locations/us-central1/endpoints/394835391592010432"

sys_instruction = [
    "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒãƒ¼ãƒ ã‚¤ãƒ³ãƒã‚¨ãƒ ä½œå®¶ã§ã™ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(v2)ã®ä½œé¢¨ã‚’å®ˆã‚Šã€40æ–‡å­—å‰å¾Œã®5ã€œ6è¡Œè©©ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚",
    "ã€é‰„å‰‡ã€‘å¿…ãš5ã€œ6è¡Œã§æ”¹è¡Œã—ã€é€”ä¸­ã§åˆ‡ã‚‰ãšã«ã€ï¼ã€ã‚„ã€ã€‚ã€ã§çµã‚“ã§ãã ã•ã„ã€‚"
]

try:
    model = GenerativeModel(
        model_name=model_path,
        system_instruction=sys_instruction
    )
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\nã‚¨ãƒ©ãƒ¼: {e}")

# --- 3. ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.title("ğŸŒ¸ åå‰ã§ãƒã‚¨ãƒ ï¼ Ver 1.9")
st.write("æœ€æ–°ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«(v2)ã‚’æ­è¼‰ã€‚ã‚ãªãŸã®åå‰ã«é­‚ã‚’è¾¼ã‚ã¾ã™ã€‚")

name = st.text_input("ãŠåå‰ï¼ˆæ¼¢å­—ï¼‰", "è’¼æ±°")
profile = st.text_area("äººç‰©ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "æ˜ã‚‹ãã¦å…ƒæ°—ã€‚ãƒ”ã‚¢ãƒãŒå¾—æ„ã€‚")
usage_choice = st.selectbox("ç”¨é€”", ["é‚„æš¦ç¥", "èª•ç”Ÿæ—¥", "å¤å¸Œç¥", "èª•ç”Ÿãƒ»å‘½åç¥ã„", "ãã®ä»–"])

# --- 4. ç”Ÿæˆå®Ÿè¡Œ ---
if st.button("è©©ã‚’ä½œæˆã™ã‚‹"):
    with st.spinner("AIãŒè¨€è‘‰ã‚’ç´¡ã„ã§ã„ã¾ã™..."):
        try:
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(v2)ã¨åŒã˜å½¢å¼ã§å•ã„ã‹ã‘
            prompt = f"æ¼¢å­—ï¼š{name}ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š{profile}ã€ç”¨é€”ï¼š{usage_choice}"
            
            response = model.generate_content(
                prompt,
                generation_config={
                    "max_output_tokens": 512,
                    "temperature": 0.7,
                }
            )
            
            st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¨ãƒ ")
            # æ”¹è¡Œã‚’ç¢ºå®Ÿã«åæ˜ ã•ã›ã‚‹æ•´å½¢å‡¦ç†
            raw_text = response.text
            formatted_poem = "  \n".join([line.strip() for line in raw_text.split("\n") if line.strip()])
            st.success(formatted_poem)
            
        except Exception as e:
            st.error("ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.info(f"è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±: {e}")
