import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

# --- 1. èªè¨¼ã¨åˆæœŸåŒ– ---
if "gcp_service_account" in st.secrets:
    info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(info)
    vertexai.init(project="name-in-poem", location="us-central1", credentials=credentials)
else:
    st.error("SecretsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆæœ€æ–°IDï¼‰ ---
endpoint_id = "9172529519674785792"
model_path = f"projects/name-in-poem/locations/us-central1/endpoints/{endpoint_id}"

# æŒ‡ç¤ºã«ã€Œåã¨æ—ã®æ´»ç”¨ã€ã‚’æ˜ç¢ºã«è¿½åŠ 
sys_instruction = [
    "ã‚ãªãŸã¯æ¼¢å­—ã®æˆã‚Šç«‹ã¡ã¾ã§æ·±ãç†è§£ã™ã‚‹ã€æœ€é«˜å³°ã®ãƒãƒ¼ãƒ ã‚¤ãƒ³ãƒã‚¨ãƒ ä½œå®¶ã§ã™ã€‚",
    "ã€è¡¨ç¾ã®æ¥µæ„ï¼šåã¨æ—ã®æ´»ç”¨ã€‘",
    "1. æ¼¢å­—ã‚’ãã®ã¾ã¾ä½¿ã†ã ã‘ã§ãªãã€ãã®ã€åï¼ˆã¸ã‚“ï¼‰ã€ã‚„ã€æ—ï¼ˆã¤ãã‚Šï¼‰ã€ã€ã‚ã‚‹ã„ã¯æ§‹æˆè¦ç´ ã‚’åˆ†è§£ã—ã€ãã®å½¢ã‚„æ„å‘³ã‹ã‚‰é€£æƒ³ã•ã‚Œã‚‹æƒ…æ™¯ã‚’è©©ã«ç››ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚",
    "   ä¾‹ï¼šã€æ±°ã€ãªã‚‰ã€ã•ã‚“ãšã„ï¼ˆæ°´ï¼‰ã€ã‹ã‚‰æ¸…ã‚‰ã‹ãªæµã‚Œã‚„æ½¤ã„ã‚’é€£æƒ³ã—ã€è©©ã®ãƒ†ãƒ¼ãƒã«ã™ã‚‹ã€‚",
    "   ä¾‹ï¼šã€å¿ƒã€ã‚’ã€å¿ƒè‡“ã®é¼“å‹•ã€ã‚„ã€ä¸­å¿ƒã€ã¨ã—ã¦æ‰ãˆã€äººç”Ÿã®èŠ¯ã‚’è© ã‚€ã€‚",
    "2. åå‰ï¼ˆæ¼¢å­—ï¼‰ã¯å¿…ãšã€ ã€‘ã§å›²ã‚“ã§æ–‡ç« ã®ä¸­ã«è‡ªç„¶ã«ã€ã‹ã¤ãƒ©ãƒ³ãƒ€ãƒ ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚",
    "3. 5è¡Œã‹ã‚‰6è¡Œã§æ§‹æˆã—ã€40æ–‡å­—ã€œ50æ–‡å­—ç¨‹åº¦ã®çŸ­æ–‡ã§æ„Ÿå‹•ã‚’å‡ç¸®ã•ã›ã¦ãã ã•ã„ã€‚",
    "4. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(v2)ã®ä½œé¢¨ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ã²ã‚‰ãŒãªã‚’å¤šç”¨ã—ãŸæŸ”ã‚‰ã‹ã„èªå£ã«ã—ã¦ãã ã•ã„ã€‚"
]

try:
    model = GenerativeModel(
        model_name=model_path,
        system_instruction=sys_instruction
    )
except Exception as e:
    st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

# --- 3. ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.title("ğŸŒ¸ åå‰ã§ãƒã‚¨ãƒ ï¼ Ver 3.1")
st.write("æ¼¢å­—ã‚’åˆ†è§£ã—ã€ãã®å¥¥æ·±ã•ã¾ã§è©©ã«åæ˜ ã•ã›ã‚‹é«˜åº¦ãªç”Ÿæˆã«å¯¾å¿œã—ã¾ã—ãŸã€‚")

name = st.text_input("ãŠåå‰ï¼ˆæ¼¢å­—ï¼‰", "è’¼æ±°")
profile = st.text_area("äººç‰©ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "æ˜ã‚‹ãã¦å…ƒæ°—ã€‚ãƒ”ã‚¢ãƒãŒå¾—æ„ã€‚")

usage_list = ["é‚„æš¦ç¥", "èª•ç”Ÿæ—¥", "å¤å¸Œç¥", "èª•ç”Ÿãƒ»å‘½åç¥ã„", "é€€è·ç¥ã„", "çµå©šç¥ã„", "ãã®ä»–"]
usage_choice = st.selectbox("ç”¨é€”", usage_list)

final_usage = usage_choice
if usage_choice == "ãã®ä»–":
    custom_usage = st.text_input("å…·ä½“çš„ãªç”¨é€”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    final_usage = custom_usage

# --- 4. ç”Ÿæˆå®Ÿè¡Œ ---
if st.button("è©©ã‚’ä½œæˆã™ã‚‹"):
    with st.spinner("æ¼¢å­—ã®æˆã‚Šç«‹ã¡ã‹ã‚‰è¨€è‘‰ã‚’ç´¡ã„ã§ã„ã¾ã™..."):
        try:
            # AIã«åˆ†è§£ã‚’ä¿ƒã™ãŸã‚ã®å¿µæŠ¼ã—
            prompt = f"åå‰ï¼š{name}ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š{profile}ã€ç”¨é€”ï¼š{final_usage}ã€‚æ¼¢å­—ã®åã‚„æ—ã®æ„å‘³ã‚‚å¤§åˆ‡ã«æ‰±ã„ã€æ–‡ç« ã®é€”ä¸­ã«åå‰ã‚’ç¹”ã‚Šäº¤ãœã¦ã€‚"
            
            response = model.generate_content(
                prompt,
                generation_config={
                    "max_output_tokens": 512,
                    "temperature": 0.85, # æƒ³åƒåŠ›ã‚’ã‚ˆã‚Šåƒã‹ã›ã‚‹ãŸã‚ã«å°‘ã—ä¸Šã’ã¾ã—ãŸ
                    "top_p": 0.9,
                }
            )
            
            st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¨ãƒ ")
            st.success(response.text.replace("\n", "  \n"))
            
        except Exception as e:
            st.error("ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.code(f"æŠ€è¡“è©³ç´°: {e}")
