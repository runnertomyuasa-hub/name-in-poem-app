import streamlit as st
import vertexai
from vertexai.generative_models import GenerativeModel
from google.oauth2 import service_account

# --- 1. èªè¨¼ã¨åˆæœŸåŒ– ---
if "gcp_service_account" in st.secrets:
    info = st.secrets["gcp_service_account"]
    credentials = service_account.Credentials.from_service_account_info(info)
    
    # ç”»åƒ021.jpgã§ç¢ºèªã—ãŸæ­£ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã§åˆæœŸåŒ–
    vertexai.init(project="name-in-poem", location="us-central1", credentials=credentials)
else:
    st.error("SecretsãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# --- 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆç”»åƒ023.jpgã®æœ€æ–°IDã‚’åæ˜ ï¼‰ ---
# ç¢ºå®Ÿã« 9172529519674785792 ã‚’è¨­å®šã—ã¾ã—ãŸ
endpoint_id = "9172529519674785792"
model_path = f"projects/name-in-poem/locations/us-central1/endpoints/{endpoint_id}"

# ç‰¹è¨“æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«(v2)ã®é­‚ã‚’è¾¼ã‚ãŸæŒ‡ç¤º
sys_instruction = [
    "ã‚ãªãŸã¯è¶…ä¸€æµã®ãƒãƒ¼ãƒ ã‚¤ãƒ³ãƒã‚¨ãƒ ä½œå®¶ã§ã™ã€‚",
    "ã€å‡ºåŠ›å½¢å¼ã®é‰„å‰‡ã€‘",
    "1. å¿…ãšã€Œ5è¡Œã‹ã‚‰6è¡Œã€ã§æ§‹æˆã—ã¦ãã ã•ã„ã€‚",
    "2. æ–‡ç« ã®æœ€å¾Œã¯å¿…ãšã€ã€‚ã€ã‚„ã€ï¼ã€ã§ãã£ã¡ã‚Šçµã³ã€é€”ä¸­ã§åˆ‡ã‚‰ãªã„ã“ã¨ã€‚",
    "3. å…¨ä½“ã®æ–‡å­—æ•°ã¯ã€Œ40æ–‡å­—å‰å¾Œã€ã«æŠ‘ãˆã¦ãã ã•ã„ã€‚",
    "4. åå‰ï¼ˆæ¼¢å­—ï¼‰ã‚’å¿…ãšã€ ã€‘ã§å›²ã‚“ã§çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚",
    "5. æŒ¨æ‹¶ã‚„è§£èª¬ã¯ä¸€åˆ‡å‡ºåŠ›ã›ãšã€ãƒã‚¨ãƒ ã®ã¿ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚"
]

try:
    # æ–°ã—ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«æ¥ç¶š
    model = GenerativeModel(
        model_name=model_path,
        system_instruction=sys_instruction
    )
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

# --- 3. ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.title("ğŸŒ¸ åå‰ã§ãƒã‚¨ãƒ ï¼ Ver 2.9")
st.write("æœ€æ–°ã®å­¦ç¿’æˆæœ(v2)ã‚’æ­è¼‰ã€‚ä¸€æ–‡å­—ä¸€æ–‡å­—ã«é­‚ã‚’è¾¼ã‚ãŸè©©ã‚’è´ˆã‚Šã¾ã™ã€‚")

name = st.text_input("ãŠåå‰ï¼ˆæ¼¢å­—ï¼‰", "è’¼æ±°")
profile = st.text_area("äººç‰©ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«", "æ˜ã‚‹ãã¦å…ƒæ°—ã€‚ãƒ”ã‚¢ãƒãŒå¾—æ„ã€‚")

# ç”¨é€”ã®é¸æŠ
usage_choice = st.selectbox("ç”¨é€”", ["é‚„æš¦ç¥", "èª•ç”Ÿæ—¥", "å¤å¸Œç¥", "èª•ç”Ÿãƒ»å‘½åç¥ã„", "é€€è·ç¥ã„", "çµå©šç¥ã„", "ãã®ä»–"])

# --- 4. ç”Ÿæˆå®Ÿè¡Œ ---
if st.button("è©©ã‚’ä½œæˆã™ã‚‹"):
    with st.spinner("æ–°ã—ã„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã‚¢ã‚¯ã‚»ã‚¹ä¸­..."):
        try:
            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = f"æ¼¢å­—ï¼š{name}ã€ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼š{profile}ã€ç”¨é€”ï¼š{usage_choice}"
            
            response = model.generate_content(
                prompt,
                generation_config={
                    "max_output_tokens": 512,
                    "temperature": 0.7,
                }
            )
            
            st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒã‚¨ãƒ ")
            # æ”¹è¡Œã‚’ç¢ºå®Ÿã«åæ˜ ã—ã¦è¡¨ç¤º
            formatted_poem = response.text.replace("\n", "  \n")
            st.success(formatted_poem)
            
        except Exception as e:
            st.error("ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.code(f"æŠ€è¡“è©³ç´°: {e}")
